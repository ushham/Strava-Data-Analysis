{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsvaK-kTr4NR"
   },
   "source": [
    "# Good-looking Elevation Graphing\n",
    "The point of this project is to make simplified but useful elevation graphs. This will also combine multiple rides into a single elevation profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XTsm60YsZqL"
   },
   "source": [
    "Point the notebook to the file the gpx files are sitting in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJKn2mySsiGX"
   },
   "outputs": [],
   "source": [
    "my_folder = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rj-dHce5soF6"
   },
   "source": [
    "We import some librarys that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_OasapszsuD3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gpxpy as gp\n",
    "from gpxpy.geo import distance\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlAAN5vB-xNc"
   },
   "source": [
    "First we choose which files to read. The defualt is to read every gpx in the folder specified, but you can also provide a list of the files you want to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDunz9zs-0ds"
   },
   "outputs": [],
   "source": [
    "data_files = [] # populate this list if you want to specify only certain files in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VAJRsLIN_IqD"
   },
   "outputs": [],
   "source": [
    "if len(data_files) == 0:\n",
    "    data_files = os.listdir(my_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpx_files = list()\n",
    "for file in data_files:\n",
    "    gpx_file = open(my_folder + '/' + file, 'r')\n",
    "    gpx_files.append(gp.parse(gpx_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = list()\n",
    "for gpx in gpx_files:\n",
    "    for track in gpx.tracks:\n",
    "        for segment in track.segments:\n",
    "            for point in segment.points:\n",
    "                temp_data.append([point.time, point.latitude, point.longitude, point.elevation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.DataFrame(temp_data, columns=['time', 'lat', 'lon', 'ele'])\n",
    "total_data['date'] = total_data['time'].dt.date\n",
    "total_data = total_data.sort_values(by=['time'])\n",
    "\n",
    "# Calculate distance\n",
    "temp_dist = [0]\n",
    "temp_ele = [0]\n",
    "for (ix1, row1), (ix2, row2) in zip(total_data.iloc[:-1].iterrows(), total_data.iloc[1:].iterrows()):\n",
    "    temp_dist.append(distance(\n",
    "                        latitude_1=row1['lat'],\n",
    "                        longitude_1=row1['lon'], \n",
    "                        elevation_1=None,\n",
    "                        latitude_2=row2['lat'],\n",
    "                        longitude_2=row2['lon'], \n",
    "                        elevation_2=None))\n",
    "    temp_ele.append(row2['ele'] - row1['ele'])\n",
    "\n",
    "total_data['dist'] = temp_dist\n",
    "total_data['ele_delta'] = temp_ele\n",
    "\n",
    "total_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "_tcz4N0nr0hj",
    "outputId": "99fdf4ff-79a4-42a5-c5db-c0c574201406"
   },
   "outputs": [],
   "source": [
    "#find unique dates\n",
    "day = 19\n",
    "dates = total_data['date'].unique()\n",
    "# pd.options.mode.chained_assignment = None\n",
    "\n",
    "un_day = total_data[total_data['date'].isin(dates[:])]\n",
    "un_day['CumDist'] = un_day['dist'].cumsum()\n",
    "un_day\n",
    "\n",
    "plt.plot(un_day['CumDist'] / 1000, un_day['ele'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yqz3zqXGyDM1"
   },
   "source": [
    "A simple rolling average with radius of x metres, and fill in the gaps using linear interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "k3X3Wi1tySef",
    "outputId": "926ce4cc-4dee-4621-ee2b-6df06373b3eb"
   },
   "outputs": [],
   "source": [
    "x = 1000 #rolling average across points within x metres\n",
    "\n",
    "day_dist = un_day['CumDist'].max()\n",
    "\n",
    "nodes = int(day_dist / x)\n",
    "\n",
    "points = np.linspace(0, day_dist, num=nodes)\n",
    "hold_ave = np.zeros(nodes)\n",
    "\n",
    "idx = 0\n",
    "for d in points:\n",
    "  #filter dataframe to find elevations in distance bound\n",
    "  dist_band = un_day[(un_day['CumDist'] > d - x / 2) & (un_day['CumDist'] <= d + x / 2)]\n",
    "  hold_ave[idx] = dist_band['ele'].mean()\n",
    "  if idx == 0:\n",
    "    hold_ave[idx] = un_day['ele'].iloc[0]\n",
    "  idx += 1\n",
    "\n",
    "#linear interpolation\n",
    "for i in range(hold_ave.shape[0]):\n",
    "  fwd = 1\n",
    "  if not(np.isnan(hold_ave[i])):\n",
    "    prev_num = hold_ave[i]\n",
    "  else:\n",
    "    while  np.isnan(hold_ave[i + fwd]):\n",
    "      fwd += 1\n",
    "\n",
    "    end_num = hold_ave[i + fwd]\n",
    "    delta = (end_num - prev_num) / fwd\n",
    "\n",
    "    hold_ave[i] = prev_num + delta\n",
    "\n",
    "print(hold_ave.shape)\n",
    "plt.plot(points / 1000, hold_ave)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05iVrtsqmScq"
   },
   "source": [
    "To smooth out the sharp corners we will now appoximate these graphs with a polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "sqtfLen7mbKi",
    "outputId": "4e32068e-3506-4175-cb37-d6d5d5ca5034"
   },
   "outputs": [],
   "source": [
    "from scipy import interpolate as it\n",
    "\n",
    "new_x = np.linspace(0, day_dist, 500)\n",
    "\n",
    "smooth_ave = it.InterpolatedUnivariateSpline(points, hold_ave)\n",
    "sm = smooth_ave(new_x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "plt.plot(un_day['CumDist'] / 1000, un_day['ele'])\n",
    "ax.plot(new_x/1000, sm)\n",
    "ax.plot(points/1000, hold_ave, linestyle='dashed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBQC0TNstl63"
   },
   "source": [
    "We only want to pick the max points at local maxima/minima, where this local variation in height is significant. To do this we need to identify these maxima/minima, and select if these are significant variations. If the point is not a maxima/minima, we take the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 767
    },
    "id": "oUreT9W-vM6_",
    "outputId": "61ba406b-8a26-470d-fd56-f2868a984b12"
   },
   "outputs": [],
   "source": [
    "#look for areas that are +-x metres from average in original data\n",
    "edit_arr = np.copy(hold_ave)\n",
    "diff = 10\n",
    "\n",
    "count = 0\n",
    "for d in points[1:-1]:\n",
    "  #find value of before and after point\n",
    "  try:\n",
    "    id1, id2 = un_day[un_day['CumDist'] <= d]['CumDist'].idxmax(), un_day[un_day['CumDist'] > d]['CumDist'].idxmin()\n",
    "\n",
    "    x1, x2 = un_day['CumDist'].loc[id1], un_day['CumDist'].loc[id2]\n",
    "    y1, y2 = un_day['ele'].loc[id1], un_day['ele'].loc[id2]\n",
    "\n",
    "    new_h = (y2 - y1) / (x2 - x1) * (d - x1) + y1\n",
    "\n",
    "    count += 1\n",
    "    id_arr = np.where(points == d)\n",
    "    if abs(new_h - hold_ave[id_arr]) > diff:\n",
    "      edit_arr[id_arr] = new_h\n",
    "  except:\n",
    "    print('Nope')\n",
    "smoother = it.InterpolatedUnivariateSpline(points, edit_arr)\n",
    "new_x = np.linspace(0, day_dist, 1000)\n",
    "sm = smoother(new_x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 10))\n",
    "ax.plot(un_day['CumDist'], un_day['ele'], color='grey')\n",
    "\n",
    "ax.plot(points, hold_ave, linestyle='dashed')\n",
    "ax.plot(points, edit_arr, linestyle='dashed')\n",
    "ax.plot(new_x, sm, linestyle=':')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 750
    },
    "id": "7FJ-k-7Y9A8y",
    "outputId": "50943011-e474-4622-f119-4755325c4be8"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 10))\n",
    "ax.plot(un_day['CumDist']/1000, un_day['ele'], linestyle=':', color='grey')\n",
    "ax.plot(new_x/1000, sm, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGZofowkBpgG"
   },
   "source": [
    "We want to find cumulative climbing done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvK7NgGI3OzO"
   },
   "outputs": [],
   "source": [
    "un_day['date'] = pd.to_datetime(un_day['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iG-OdC5WA1ym"
   },
   "outputs": [],
   "source": [
    "unique_dates = un_day['date'].dt.date.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of the cumulative climbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clm = np.empty(len(un_day))\n",
    "clm[0] = un_day['ele_delta'].iloc[0] if un_day['ele_delta'].iloc[0] > 0 else 0\n",
    "for i in range(1, len(un_day)):\n",
    "  if un_day['ele_delta'].iloc[i] > 0:\n",
    "    clm[i] = clm[i - 1] + un_day['ele_delta'].iloc[i]\n",
    "  else:\n",
    "    clm[i] = clm[i - 1]\n",
    "\n",
    "un_day['CumEle'] = clm - clm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 710
    },
    "id": "NHTwRz0LBulx",
    "outputId": "9362685e-7492-4fe6-eca3-1d4c3a70b555"
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(18, 10))\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "plt_cl = \"blue\"\n",
    "\n",
    "\n",
    "# Plot ticks for daily distance\n",
    "for d in unique_dates:\n",
    "  dlta = 200\n",
    "  dist = un_day[un_day['date'].dt.date == d]['CumDist'].min()\n",
    "  cum_ele = un_day[un_day['CumDist'] == dist]['CumEle']\n",
    "  ax2.vlines(dist/1000, cum_ele - dlta, cum_ele + dlta)\n",
    "\n",
    "ax1.plot(new_x/1000, sm, color=plt_cl, label='Actual Elevation')\n",
    "ax2.plot((un_day['CumDist'])/1000, un_day['CumEle'], color='grey', label='Cumulative Climbing')\n",
    "\n",
    "ax1.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "ax1.set_xlabel('Distance (km)', size=15)\n",
    "ax1.set_ylabel('Elevation above sea level (m)', c=plt_cl, size=15)\n",
    "ax2.set_ylabel('Cumulative Elevation (m)', c='grey', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tdd8eo4_NXtg"
   },
   "source": [
    "Save Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpMxfyolNZaN"
   },
   "outputs": [],
   "source": [
    "saveloc = ''\n",
    "\n",
    "fig.savefig(saveloc, dpi=600)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
